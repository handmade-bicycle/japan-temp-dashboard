{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import ssl\n",
    "\n",
    "#avoid error from SSL Certificate\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical(area, data_type):\n",
    "    \n",
    "    area_name = \"\"\n",
    "    local_counter = 0\n",
    "    d = data_type\n",
    "\n",
    "    for year in np.arange(1976,2021):\n",
    "        \n",
    "        #get url with area ID and year ID\n",
    "        url = \"https://www.data.jma.go.jp/obd/stats/etrn/view/monthly_h1.php?prec_no=\"+ str(area) +\"&block_no=00&year=\" + str(year) + \"&month=1&day=&view=p\" + str(d)\n",
    "        \n",
    "        #collect html data from the url\n",
    "        response = request.urlopen(url)\n",
    "        soup = BeautifulSoup(response)\n",
    "        \n",
    "        #collect table data\n",
    "        #if the url does not contain table data, skip to the next year\n",
    "        try:\n",
    "            table = soup.findAll('table')[4]\n",
    "        \n",
    "        except IndexError:\n",
    "            year +=1\n",
    "            continue\n",
    "            \n",
    "        #get area name\n",
    "        header = soup.findAll(\"h3\")\n",
    "\n",
    "\n",
    "        for name in header:\n",
    "            h = name.text\n",
    "            area_name = re.split(\"\\地方|\\都|\\府|\\県\",h)[0]\n",
    "\n",
    "        #get indices (yyyy-mm-15 for 1974-2020)\n",
    "        index_list = []\n",
    "        names = table.find_all('a')\n",
    "\n",
    "\n",
    "        for name in names:\n",
    "            text = name.text\n",
    "            index_list.append(text)\n",
    "\n",
    "        index_list = [str(year) + \"-\" + i + \"-\" + \"15\" for i in index_list]\n",
    "        index_num = len(index_list)\n",
    "\n",
    "        #get columns (observation points)\n",
    "        col_list = []\n",
    "        names = table.find_all(\"th\")\n",
    "        \n",
    "        for name in names:\n",
    "            text = name.text\n",
    "            col_list.append(text)\n",
    "            \n",
    "        #get rid of the first column\n",
    "        col_list = col_list[1:]\n",
    "        \n",
    "        #get number of columns for the calculation afterwards\n",
    "        col_num = len(col_list) + 1\n",
    "\n",
    "\n",
    "        #get row data\n",
    "        row_list = []\n",
    "        values = table.find_all(\"td\")\n",
    "\n",
    "\n",
    "        for i in np.arange(index_num):\n",
    "            row = values[1 + i*col_num : col_num + i*col_num]\n",
    "            row = [x.text for x in row]\n",
    "            row_list.append(row)\n",
    "            \n",
    "        #creat local_df as pd.DataFrame\n",
    "        local_df = pd.DataFrame(row_list, index=index_list, columns=col_list)\n",
    "        \n",
    "        #choose the first column if there are name collisions for observation points\n",
    "        local_df = local_df.loc[:,  local_df.columns.duplicated() == False]\n",
    "        \n",
    "        #copy local df to df if it's the first iteration\n",
    "        if local_counter==0:\n",
    "            df = local_df\n",
    "            local_counter+=1\n",
    "        else:\n",
    "            \n",
    "            #add rows with nan if observation points are newly added\n",
    "            for col in local_df.columns:\n",
    "                \n",
    "                if col not in df.columns:\n",
    "                    df[col] = np.nan           \n",
    "            \n",
    "            #concat df and loacal_df\n",
    "            df = pd.concat([df, local_df], axis=0)\n",
    "        \n",
    "        year +=1\n",
    "    \n",
    "    if area==17:\n",
    "        area_name = \"ｵﾎｰﾂｸ\"\n",
    "        \n",
    "    if area_name == \"京\":\n",
    "        area_name = \"京都\"\n",
    "        \n",
    "    return df, area_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(start=11, end=92, d=2):\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    for n in np.arange(start,end):\n",
    "        \n",
    "        try:\n",
    "            l, a = get_historical(area=n, data_type=d)\n",
    "            print(\"area number {x} at {y} was successfull in being downloaded.\".format(x=n, y=a))\n",
    "            \n",
    "        except:\n",
    "            print(\"area number {} was not avairable.\".format(n))\n",
    "            continue\n",
    "\n",
    "        local_df = l.T\n",
    "        local_df.index = pd.Series(local_df.index, name=\"point\")\n",
    "        local_df[\"area\"] = a\n",
    "        local_df.set_index([\"area\"],append=True,inplace=True)\n",
    "        local_df = local_df.swaplevel(\"area\",\"point\")\n",
    "                \n",
    "        if counter == 0:\n",
    "            df = local_df\n",
    "            counter += 1\n",
    "        else:\n",
    "            df = pd.concat([df,local_df])\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    \n",
    "    df = df.replace(\"///\", np.nan)\n",
    "    df = df.replace(\"×\", np.nan)\n",
    "    df = df.replace(\"\", np.nan)\n",
    "    df = df.replace(\" \", np.nan)\n",
    "    df = df.replace(np.nan,\"nan\")\n",
    "    \n",
    "    for i in np.arange(0,len(df.columns)):\n",
    "        df.iloc[:,i] = df.iloc[:,i].map(str)\n",
    "        df.iloc[:,i] = df.iloc[:,i].map(lambda x: re.split(\"\\)|\\]|\\.|\\uff08\",x)[0])\n",
    "\n",
    "    for i in np.arange(0,len(df.columns)):\n",
    "        df.iloc[:,i] = df.iloc[:,i].map(float)\n",
    "        \n",
    "        \n",
    "    #modify index names\n",
    "    df.reset_index(inplace=True) \n",
    "    \n",
    "    #remove \"*\" from column names    \n",
    "    df[\"point\"] = df[\"point\"].map(lambda x: re.split(\"\\*|\\.\",x)[0])\n",
    "    \n",
    "    #replace some point names\n",
    "    df = df.replace(\"奥日光（日光）\", \"奥日光\")\n",
    "    df = df.replace(\"南大東（南大東島）\", \"南大東\")\n",
    "    df = df.replace(\"つくば（館野）\", \"つくば\")\n",
    "    \n",
    "    df.set_index([\"area\",\"point\"], inplace=True)\n",
    "        \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
